{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d12ba7f4-6184-48f1-88ae-3ba7812c7202",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import make_scorer \n",
    "\n",
    "# Function for score by RMSE\n",
    "def rmse(predict, actual):\n",
    "    predict = np.array(predict)\n",
    "    actual = np.array(actual)\n",
    "\n",
    "    distance = predict - actual\n",
    "\n",
    "    square_distance = distance ** 2\n",
    "\n",
    "    mean_square_distance = square_distance.mean()\n",
    "\n",
    "    score = np.sqrt(mean_square_distance)\n",
    "\n",
    "    return score\n",
    "\n",
    "rmse_score = make_scorer(rmse, greater_is_better = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5393a210-2ee0-460c-8a3c-8c22d50cd695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data files\n",
    "data = pd.read_csv('i.csv', header = None, float_precision='high', sep = ';', dtype = np.float64)\n",
    "target = pd.read_csv('o.csv', header = None, float_precision='high', sep = ';', dtype = np.float64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "619b0de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# set some random\n",
    "np.random.seed(76213)\n",
    "\n",
    "# normalize features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data) \n",
    "scaled_df = scaler.transform(data)\n",
    "\n",
    "# make train data\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_df, target, test_size=0.33, random_state=42)\n",
    "y_train = np.ravel(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "746fcd4d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[95], line 17\u001b[0m\n\u001b[1;32m      7\u001b[0m param_grid \u001b[39m=\u001b[39m {\n\u001b[1;32m      8\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mhidden_layer_sizes\u001b[39m\u001b[39m'\u001b[39m: [(\u001b[39m24\u001b[39m), (\u001b[39m24\u001b[39m,\u001b[39m24\u001b[39m), (\u001b[39m24\u001b[39m,\u001b[39m24\u001b[39m,\u001b[39m24\u001b[39m)],\n\u001b[1;32m      9\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mmax_iter\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m7000\u001b[39m, \u001b[39m10000\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mlearning_rate\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m'\u001b[39m\u001b[39madaptive\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     14\u001b[0m }\n\u001b[1;32m     16\u001b[0m grid \u001b[39m=\u001b[39m GridSearchCV(mlp_reg, param_grid, n_jobs\u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, cv\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m grid\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     19\u001b[0m \u001b[39mprint\u001b[39m(grid\u001b[39m.\u001b[39mbest_params_) \n\u001b[1;32m     21\u001b[0m grid_predictions \u001b[39m=\u001b[39m grid\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    869\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    871\u001b[0m     )\n\u001b[1;32m    873\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 875\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    877\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    879\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1389\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1387\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1388\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1389\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    815\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    817\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    819\u001b[0m         )\n\u001b[1;32m    820\u001b[0m     )\n\u001b[0;32m--> 822\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    823\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    824\u001b[0m         clone(base_estimator),\n\u001b[1;32m    825\u001b[0m         X,\n\u001b[1;32m    826\u001b[0m         y,\n\u001b[1;32m    827\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    828\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    829\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    830\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    831\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    832\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    833\u001b[0m     )\n\u001b[1;32m    834\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    835\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    836\u001b[0m     )\n\u001b[1;32m    837\u001b[0m )\n\u001b[1;32m    839\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    840\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    844\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[1;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[1;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m    449\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m--> 451\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    454\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mlp_reg = MLPRegressor(hidden_layer_sizes=(150,100,50),\n",
    "                       max_iter = 300,activation = 'relu',\n",
    "                       solver = 'adam')\n",
    "\n",
    "# mlp_reg.fit(X_train, y_train)\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(24), (24,24), (24,24,24)],\n",
    "    'max_iter': [7000, 10000],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['lbfgs', 'adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['adaptive'],\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(mlp_reg, param_grid, n_jobs= -1, cv=3, scoring=rmse_score)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(grid.best_params_) \n",
    "\n",
    "grid_predictions = grid.predict(X_test)\n",
    "\n",
    "df_temp2 = pd.DataFrame({'Actual': y_test, 'Predicted': grid_predictions})\n",
    "df_temp2.head()\n",
    "\n",
    "df_temp2 = df_temp2.head(30)\n",
    "df_temp2.plot(kind='bar',figsize=(10,6))\n",
    "plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\n",
    "plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a49317",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# SGD regressor (best: 0.00138)\n",
    "SGDReg = SGDRegressor(tol=0.0001, learning_rate='adaptive')\n",
    "SGDReg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"Train SGDReg RMSE: {}\".format((mean_squared_error(y_train, SGDReg.predict(X_train),squared=False))))\n",
    "print(\"Test SGDReg RMSE: {}\".format((mean_squared_error(y_test, SGDReg.predict(X_test),squared=False))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7670b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Define base regressor:\n",
    "# base_reg = MLPRegressor(learning_rate='adaptive', max_iter=7000, random_state=42)\n",
    "\n",
    "# # Define search space:\n",
    "# params = {\n",
    "#     'activation': ['logistic', 'relu', 'tanh'],  # <-- added 'tanh' as third non-linear activation function\n",
    "#     'alpha': np.logspace(0.0001, 100, 10)\n",
    "#     # 'hidden_layer_sizes': [\n",
    "#     #     (10, 10), (20, 10), (30, 10)\n",
    "#     #     # (40, 10), (90, 10), (90, 30, 10)  # <-- added more neurons or layers\n",
    "#     # ]\n",
    "# }\n",
    "\n",
    "# # Find best hyper params and then refit on all training data:\n",
    "# reg = GridSearchCV(estimator=base_reg, param_grid=params,\n",
    "#                    n_jobs=4, cv=3, refit=True, verbose=5,\n",
    "#                    scoring=mean_squared_error)  # <-- verbose=5\n",
    "# reg.fit(X_train, y_train)\n",
    "\n",
    "# print(reg.best_estimator_)\n",
    "\n",
    "# print(reg.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c02d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# # MLPRegressor\n",
    "# mlpReg = MLPRegressor(alpha=1.0002302850208247, learning_rate='adaptive', max_iter=7000,\n",
    "#              random_state=42,activation='relu')\n",
    "\n",
    "# # MLPRegressor(activation='relu',            # ‘identity’, ‘logistic’, ‘tanh’, ‘relu’\n",
    "# #                         solver='adam',             #‘lbfgs’, ‘sgd’, ‘adam’   \n",
    "# #                         batch_size='auto',          \n",
    "# #                         learning_rate='adaptive',   \n",
    "# #                         max_iter=10000,\n",
    "# #                         random_state=42,\n",
    "# #                         tol=0.0001)\n",
    "\n",
    "# mlpReg.fit(X_train, y_train)\n",
    "\n",
    "# train_mse_MLPRegressor = mean_squared_error(y_train, mlpReg.predict(X_train),squared=False)\n",
    "# test_mse_MLPRegressor = mean_squared_error(y_test, mlpReg.predict(X_test),squared=False)\n",
    "\n",
    "# print(\"Train MLPRegressor RMSE: {}\".format((train_mse_MLPRegressor)))\n",
    "# print(\"Test MLPRegressor RMSE: {}\".format((test_mse_MLPRegressor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff7d6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# params = {\n",
    "#     \"activation\" : ['identity', 'logistic', 'tanh', 'relu'],\n",
    "#     \"solver\" : ['adam', 'lbfgs', 'sgd'],\n",
    "#     \"learning_rate\" : ['adaptive', 'invscaling']\n",
    "# }\n",
    "\n",
    "# # Find best hyper params and then refit on all training data:\n",
    "# reg = GridSearchCV(estimator=mlpReg, \n",
    "#                     param_grid=params,\n",
    "#                     # cv=3, \n",
    "#                     refit=True, \n",
    "#                     verbose=5,\n",
    "#                     n_jobs=4,\n",
    "#                     scoring='neg_mean_squared_error')\n",
    "\n",
    "# # Поиск оптимальных параметров\n",
    "# reg.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883df5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(\"Лучшие параметры: {}\".format(reg.best_params_)) \n",
    "# print(\"Лучшая оценка RMSE: {}\".format(reg.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097ad886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # MLPRegressor\n",
    "# optimalReg = MLPRegressor(activation='relu',            # ‘identity’, ‘logistic’, ‘tanh’, ‘relu’\n",
    "#                         solver='adam',                   #‘lbfgs’, ‘sgd’, ‘adam’   \n",
    "#                         learning_rate='adaptive',   \n",
    "#                         max_iter=7000,\n",
    "#                         random_state=42)\n",
    "\n",
    "# optimalReg.fit(X_train, y_train)\n",
    "\n",
    "# trainRmseOptimalReg = mean_squared_error(y_train, optimalReg.predict(X_train),squared=False)\n",
    "# testRmseOptimalReg = mean_squared_error(y_test, optimalReg.predict(X_test),squared=False)\n",
    "\n",
    "# print(\"optimalReg model train data RMSE: {}\".format((trainRmseOptimalReg)))\n",
    "# print(\"optimalReg model test data: {}\".format((testRmseOptimalReg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cf6311",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# sorted(list(zip(data.columns, model.coef_)), \n",
    "#        key=lambda x: abs(x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000b78d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# save the model to disk\n",
    "# filenameModel = 'finalized_model.sav'\n",
    "# pickle.dump(optimalReg, open(filenameModel, 'wb'))\n",
    " \n",
    "# fiilenameParams = 'modelParams.sav'\n",
    "# pickle.dump(reg.best_params_, open(fiilenameParams, 'wb'))\n",
    "# some time later...\n",
    " \n",
    "# load the model from disk\n",
    "# loaded_model = pickle.load(open(filename, 'r'))\n",
    "# result = loaded_model.score(X_test, y_test)\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0ce0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_model = pickle.load(open(filenameModel, 'rb'))\n",
    "\n",
    "# trainRmseLoadadModel = mean_squared_error(y_train, loaded_model.predict(X_train),squared=False)\n",
    "# testRmseLodedModel = mean_squared_error(y_test, loaded_model.predict(X_test),squared=False)\n",
    "\n",
    "# print(\"Loadaed model train data RMSE: {}\".format((trainRmseLoadadModel)))\n",
    "# print(\"Loadaed model test data: {}\".format((testRmseLodedModel)))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
